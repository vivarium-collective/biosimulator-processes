{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:46:57.177373Z",
     "start_time": "2024-09-09T19:46:53.349467Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "from process_bigraph import Composite\n",
    "\n",
    "from biosimulators_processes import CORE\n",
    "from biosimulators_processes.steps.bio_compose import MongoDatabaseEmitter\n",
    "from process_bigraph.composite import RAMEmitter\n",
    "from biosimulators_processes.processes.copasi_process import CopasiProcess"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:41:56.426932Z",
     "start_time": "2024-09-09T19:41:56.413484Z"
    }
   },
   "source": [
    "uri = 'mongodb://localhost:27017/?retryWrites=true&w=majority&appName=biosimulators-processes'\n",
    "emitter = MongoDatabaseEmitter(config={'connection_uri': uri}, core=CORE)\n",
    "ram = RAMEmitter(config={}, core=CORE)\n",
    "ram.inputs()"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:46:58.609152Z",
     "start_time": "2024-09-09T19:46:58.605950Z"
    }
   },
   "source": [
    "model_fp = '/Users/alexanderpatrie/Desktop/repos/biosimulator-processes/test_suite/examples/sbml-core/Elowitz-Nature-2000-Repressilator/BIOMD0000000012_url.xml'"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:46:59.209847Z",
     "start_time": "2024-09-09T19:46:59.132176Z"
    }
   },
   "source": [
    "doc = {\n",
    "    'copasi': {\n",
    "        '_type': 'process',\n",
    "        'address': 'local:copasi-process',\n",
    "        'config': {\n",
    "            'model': {\n",
    "                'model_source': model_fp\n",
    "            }\n",
    "        },\n",
    "        'inputs': {\n",
    "            'time': ['time_store'],\n",
    "            'floating_species_concentrations': ['floating_species_concentrations_store'],\n",
    "            'model_parameters': ['model_parameters_store'],\n",
    "            'reactions': ['reactions_store']\n",
    "        },\n",
    "        'outputs': {\n",
    "            'time': ['time_store'],\n",
    "            'floating_species_concentrations': ['floating_species_concentrations_store'],\n",
    "        }\n",
    "    },\n",
    "    'emitter': {\n",
    "        '_type': 'step',\n",
    "        'address': 'local:database-emitter',\n",
    "        'config': {\n",
    "            'emit': {\n",
    "                'time': 'float',\n",
    "                'floating_species_concentrations': 'tree[float]'\n",
    "            }\n",
    "        },\n",
    "        'inputs': {\n",
    "            'time': ['time_store'],\n",
    "            'floating_species_concentrations': ['floating_species_concentrations_store']\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "composite = Composite(config={'state': doc}, core=CORE)\n",
    "\n",
    "composite.run(10)"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T19:47:00.989367Z",
     "start_time": "2024-09-09T19:47:00.983745Z"
    }
   },
   "cell_type": "code",
   "source": "composite.gather_results()",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:33:26.782379Z",
     "start_time": "2024-09-09T21:33:26.690255Z"
    }
   },
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "from typing import *\n",
    "from datetime import datetime\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from pymongo.collection import Collection\n",
    "from pymongo.database import Database\n",
    "\n",
    "\n",
    "class DatabaseConnector(ABC):\n",
    "    \"\"\"Abstract class that is both serializable and interacts with the database (of any type). \"\"\"\n",
    "    def __init__(self, connection_uri: str, database_id: str, connector_id: str):\n",
    "        self.database_id = database_id\n",
    "        self.client = self._get_client(connection_uri)\n",
    "        self.db = self._get_database(self.database_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def timestamp() -> str:\n",
    "        return str(datetime.utcnow())\n",
    "\n",
    "    def refresh_data(self):\n",
    "        def refresh_collection(coll):\n",
    "            for job in self.db[coll].find():\n",
    "                self.db[coll].delete_one(job)\n",
    "\n",
    "        for collname in self.db.list_collection_names():\n",
    "            refresh_collection(collname)\n",
    "\n",
    "    @abstractmethod\n",
    "    def _get_client(self, *args):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _get_database(self, db_id: str):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def read(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def write(self, *args, **kwargs):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def get_collection(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "\n",
    "class JobStatus(Enum):\n",
    "    PENDING = \"PENDING\"\n",
    "    IN_PROGRESS = \"IN_PROGRESS\"\n",
    "    COMPLETED = \"COMPLETED\"\n",
    "    FAILED = \"FAILED\"\n",
    "\n",
    "\n",
    "class DatabaseCollections(Enum):\n",
    "    PENDING_JOBS = \"PENDING_JOBS\".lower()\n",
    "    IN_PROGRESS_JOBS = \"IN_PROGRESS_JOBS\".lower()\n",
    "    COMPLETED_JOBS = \"COMPLETED_JOBS\".lower()\n",
    "\n",
    "\n",
    "class MultipleConnectorError(Exception):\n",
    "    def __init__(self, message: str):\n",
    "        self.message = message\n",
    "\n",
    "\n",
    "class MongoDbConnector(DatabaseConnector):\n",
    "    def __init__(self, connection_uri: str, database_id: str, connector_id: str = None):\n",
    "        super().__init__(connection_uri, database_id, connector_id)\n",
    "\n",
    "    def _get_client(self, *args):\n",
    "        return MongoClient(args[0])\n",
    "\n",
    "    def _get_database(self, db_id: str) -> Database:\n",
    "        return self.client.get_database(db_id)\n",
    "\n",
    "    def _get_jobs_from_collection(self, coll_name: str):\n",
    "        return [job for job in self.db[coll_name].find()]\n",
    "    \n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._get_data()\n",
    "    \n",
    "    def _get_data(self):\n",
    "        return {coll_name: [v for v in self.db[coll_name].find()] for coll_name in self.db.list_collection_names()}\n",
    "    \n",
    "    def read(self, collection_name: DatabaseCollections | str, **kwargs):\n",
    "        \"\"\"Args:\n",
    "            collection_name: str\n",
    "            kwargs: (as in mongodb query)\n",
    "        \"\"\"\n",
    "        coll_name = self._parse_enum_input(collection_name)\n",
    "        coll = self.get_collection(coll_name)\n",
    "        result = coll.find_one(kwargs.copy())\n",
    "        return result\n",
    "\n",
    "    def write(self, collection_name: DatabaseCollections | str, **kwargs):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                collection_name: str: collection name in mongodb\n",
    "                **kwargs: mongo db `insert_one` query defining the document where the key is as in the key of the document.\n",
    "        \"\"\"\n",
    "        coll_name = collection_name\n",
    "\n",
    "        coll = self.get_collection(coll_name)\n",
    "        result = coll.insert_one(kwargs.copy())\n",
    "        return kwargs\n",
    "\n",
    "    def get_collection(self, collection_name: str) -> Collection:\n",
    "        try:\n",
    "            return self.db[collection_name]\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    async def insert_job_async(self, collection_name: str, **kwargs) -> Dict[str, Any]:\n",
    "        return self.insert_job(collection_name, **kwargs)\n",
    "\n",
    "    def insert_job(self, collection_name: str, **kwargs) -> Dict[str, Any]:\n",
    "        coll = self.get_collection(collection_name)\n",
    "        job_doc = kwargs.copy()\n",
    "        print(\"Inserting job...\")\n",
    "        coll.insert_one(job_doc)\n",
    "        print(f\"Job successfully inserted: {self.db.pending_jobs.find_one(kwargs)}.\")\n",
    "        return kwargs\n",
    "\n",
    "    async def update_job_status(self, collection_name: str, job_id: str, status: str | JobStatus):\n",
    "        job_status = self._parse_enum_input(status)\n",
    "        return self.db[collection_name].update_one({'job_id': job_id, }, {'$set': {'status': job_status}})\n",
    "\n",
    "    def _parse_enum_input(self, _input: Any) -> str:\n",
    "        return _input.value if isinstance(_input, Enum) else _input\n"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:39:22.283816Z",
     "start_time": "2024-09-09T21:39:22.280639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from bson import ObjectId\n",
    "{'_id': str(ObjectId('66df318e3c05234ee7df709b')),\n",
    "   'job_id': 'e7619d85-c0a6-40df-9f30-e43e1a0a92fb',\n",
    "   'last_updated': '2024-09-09 17:34:06.250744'}"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:47:23.319842Z",
     "start_time": "2024-09-09T21:47:23.312379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uri = 'mongodb://localhost:27017/?retryWrites=true&w=majority&appName=biosimulators-processes'\n",
    "conn = MongoDbConnector(connection_uri=uri, database_id=\"processes\")\n",
    "\n",
    "conn.data\n",
    "\n"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:20:53.748074Z",
     "start_time": "2024-09-09T22:20:53.727491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import gridfs\n",
    "import bson \n",
    "import json \n",
    "\n",
    "job_id = 'e7619d85-c0a6-40df-9f30-e43e1a0a92fb'\n",
    "\n",
    "def format_data(conn):\n",
    "    # goes to helpers\n",
    "    formatted_data = {'process_results': []}\n",
    "    for result in conn.data['process_results']:\n",
    "        result['_id'] = str(result['_id'])\n",
    "        formatted_data['process_results'].append(result)\n",
    "    return formatted_data\n",
    "\n",
    "\n",
    "def get_fs(conn):\n",
    "    # goes to db connector\n",
    "    return gridfs.GridFS(conn.db)   \n",
    "\n",
    "\n",
    "def write_fs(conn, job_id):\n",
    "    formatted_data = format_data(conn)\n",
    "    fs = get_fs(conn)\n",
    "    serialized_json = json.dumps(formatted_data)\n",
    "    file_id = fs.put(serialized_json.encode('utf-8'), filename=job_id)\n",
    "    return file_id\n",
    "\n",
    "\n",
    "file_id = write_fs(conn, job_id)\n",
    "\n",
    "\n",
    "def read_fs(conn, file_id):\n",
    "    fs = get_fs(conn)\n",
    "    stored_file = fs.get(file_id)\n",
    "    retrieved_json = json.loads(stored_file.read().decode('utf-8'))\n",
    "    return retrieved_json"
   ],
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:20:55.237714Z",
     "start_time": "2024-09-09T22:20:55.235032Z"
    }
   },
   "cell_type": "code",
   "source": "file_id",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:13:02.462341Z",
     "start_time": "2024-09-09T22:13:02.457009Z"
    }
   },
   "cell_type": "code",
   "source": "read_fs(conn, file_id)",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:56:57.574999Z",
     "start_time": "2024-09-09T21:56:57.571469Z"
    }
   },
   "cell_type": "code",
   "source": "[j for j in conn.db['fs.files'].find()]",
   "execution_count": 21,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:53:30.405713Z",
     "start_time": "2024-09-09T21:53:30.257073Z"
    }
   },
   "cell_type": "code",
   "source": "!ls",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T17:34:06.409632Z",
     "start_time": "2024-09-09T17:34:06.236747Z"
    }
   },
   "source": [
    "# run composite with copasi process and ram emitter\n",
    "# on each update: return emitter val\n",
    "# use db connector to write emitter val for update\n",
    "# repeat\n",
    "\n",
    "\n",
    "def run_composite_sse(duration, model_fp=model_fp, core=CORE):\n",
    "    from process_bigraph import Composite \n",
    "    from uuid import uuid4\n",
    "\n",
    "    uri = 'mongodb://localhost:27017/?retryWrites=true&w=majority&appName=biosimulators-processes'\n",
    "    conn = MongoDbConnector(connection_uri=uri, database_id=\"processes\")\n",
    "    doc = {\n",
    "        'copasi': {\n",
    "            '_type': 'process',\n",
    "            'address': 'local:copasi-process',\n",
    "            'config': {\n",
    "                'model': {\n",
    "                    'model_source': model_fp\n",
    "                }\n",
    "            },\n",
    "            'inputs': {\n",
    "                'time': ['time_store'],\n",
    "                'floating_species_concentrations': ['floating_species_concentrations_store'],\n",
    "                'model_parameters': ['model_parameters_store'],\n",
    "                'reactions': ['reactions_store']\n",
    "            },\n",
    "            'outputs': {\n",
    "                'time': ['time_store'],\n",
    "                'floating_species_concentrations': ['floating_species_concentrations_store'],\n",
    "            }\n",
    "        },\n",
    "        'emitter': {\n",
    "            '_type': 'step',\n",
    "            'address': 'local:ram-emitter',\n",
    "            'config': {\n",
    "                'emit': {\n",
    "                    'time': 'float',\n",
    "                    'floating_species_concentrations': 'tree[float]'\n",
    "                }\n",
    "            },\n",
    "            'inputs': {\n",
    "                'time': ['time_store'],\n",
    "                'floating_species_concentrations': ['floating_species_concentrations_store']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # make new job \n",
    "    job_id = str(uuid4())\n",
    "    new_job = {'job_id': job_id}\n",
    "    \n",
    "    # insert mutable params\n",
    "    write_job = new_job.copy()\n",
    "    write_job.update({'last_updated': conn.timestamp(), 'data': []})\n",
    "    job = conn.write(collection_name=\"process_results\", **write_job)\n",
    "    \n",
    "    # make composite\n",
    "    composite = Composite(config={'state': doc}, core=core)\n",
    "    \n",
    "    for n in range(duration):\n",
    "        # run composite\n",
    "        composite.run(1)\n",
    "        \n",
    "        # get historical results    \n",
    "        results = composite.gather_results()\n",
    "        data = results[('emitter',)]\n",
    "        \n",
    "        # find job and update data\n",
    "        write_data = conn.db.process_results.find_one(new_job)\n",
    "        write_data['data'] = data \n",
    "        \n",
    "        # update db\n",
    "        conn.db.process_results.update_one(new_job, {'$set': write_data})\n",
    "        \n",
    "    return conn\n",
    "\n",
    "conn.refresh_data()\n",
    "conn = run_composite_sse(10)"
   ],
   "execution_count": 106,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T17:34:07.588196Z",
     "start_time": "2024-09-09T17:34:07.582650Z"
    }
   },
   "cell_type": "code",
   "source": "conn.data.get('process_results')",
   "execution_count": 107,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T17:06:01.089610Z",
     "start_time": "2024-09-09T17:06:01.076349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = [{'a': list(range(10))}, {'a': list(range(10))}]\n",
    "\n",
    "list(set(x))"
   ],
   "execution_count": 60,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T17:31:46.117355Z",
     "start_time": "2024-09-09T17:31:46.114765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s = {'a': 10}\n",
    "\n",
    "s.update({'b': 3})"
   ],
   "execution_count": 103,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T17:31:47.240692Z",
     "start_time": "2024-09-09T17:31:47.238272Z"
    }
   },
   "cell_type": "code",
   "source": "s",
   "execution_count": 104,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:26:04.607346Z",
     "start_time": "2024-09-09T22:26:00.812236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_fp = '/Users/alexanderpatrie/Desktop/repos/biosimulator-processes/test_suite/examples/smoldyn/MinE.txt'\n",
    "doc = {\n",
    "        'process': {\n",
    "            '_type': 'process',\n",
    "            'address': 'local:smoldyn-process',\n",
    "            'config': {\n",
    "                'model': {\n",
    "                    'model_source': model_fp\n",
    "                }\n",
    "            },\n",
    "            \"inputs\": {\n",
    "                \"species_counts\": [\n",
    "                  \"species_store\"\n",
    "                ],\n",
    "                \"molecules\": [\n",
    "                  \"molecules_store\"\n",
    "                ]\n",
    "              },\n",
    "              \"outputs\": {\n",
    "                \"species_counts\": [\n",
    "                  \"species_store\"\n",
    "                ],\n",
    "                \"molecules\": [\n",
    "                  \"molecules_store\"\n",
    "                ]\n",
    "              }\n",
    "            },\n",
    "            \"emitter\": {\n",
    "              \"_type\": \"step\",\n",
    "              \"address\": \"local:database-emitter\",\n",
    "              \"config\": {\n",
    "                \"emit\": {\n",
    "                  \"species_counts\": \"tree[integer]\",\n",
    "                  \"molecules\": \"tree[string]\"\n",
    "                }\n",
    "              },\n",
    "              \"inputs\": {\n",
    "                \"species_counts\": [\n",
    "                  \"species_store\"\n",
    "                ],\n",
    "                \"molecules\": [\n",
    "                  \"molecules_store\"\n",
    "                ]\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "\n",
    "from process_bigraph import Composite\n",
    "from biosimulators_processes import CORE \n",
    "CORE.process_registry.registry"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T23:09:30.053523Z",
     "start_time": "2024-09-09T23:09:30.046211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# THE goal is to be able to provide interval-wise smoldyn output files \n",
    "\n",
    "def read_smoldyn_simulation_configuration(filename):\n",
    "    ''' Read a configuration for a Smoldyn simulation\n",
    "\n",
    "    Args:\n",
    "        filename (:obj:`str`): path to model file\n",
    "\n",
    "    Returns:\n",
    "        :obj:`list` of :obj:`str`: simulation configuration\n",
    "    '''\n",
    "    with open(filename, 'r') as file:\n",
    "        return [line.strip('\\n') for line in file]\n",
    "\n",
    "\n",
    "def write_smoldyn_simulation_configuration(configuration, filename):\n",
    "    ''' Write a configuration for Smoldyn simulation to a file\n",
    "\n",
    "    Args:\n",
    "        configuration\n",
    "        filename (:obj:`str`): path to save configuration\n",
    "    '''\n",
    "    with open(filename, 'w') as file:\n",
    "        for line in configuration:\n",
    "            file.write(line)\n",
    "            file.write('\\n')\n",
    "            \n",
    "\n",
    "\n",
    "def add_output_commands(model_fp, duration):\n",
    "    config = read_smoldyn_simulation_configuration(model_fp)\n",
    "    has_output_commands = any([v.startswith('output') for v in config])\n",
    "    if not has_output_commands:\n",
    "        cmd_i = 0\n",
    "        for i, v in enumerate(config):\n",
    "            if v == 'end_file':\n",
    "                cmd_i += i - 1\n",
    "            stop_key = 'time_stop'\n",
    "            \n",
    "            if f'define {stop_key.upper()}' in v:\n",
    "                new_v = f'define TIME_STOP   {duration}'\n",
    "                config.remove(config[i])\n",
    "                config.insert(i, new_v)\n",
    "            elif v.startswith(stop_key):\n",
    "                new_v = f'time_stop TIME_STOP'\n",
    "                config.remove(config[i])\n",
    "                config.insert(i, new_v)\n",
    "        cmds = [\"output_files modelout.txt\",\n",
    "                \"cmd i 0 TIME_STOP 2 executiontime modelout.txt\",\n",
    "                \"cmd i 0 TIME_STOP 2 listmols modelout.txt\"]\n",
    "        current = cmd_i \n",
    "        for cmd in cmds:\n",
    "            config.insert(current, cmd)\n",
    "            current += 1 \n",
    "    \n",
    "    write_smoldyn_simulation_configuration(config, model_fp) \n",
    "    \n",
    "    out_file = model_fp.replace(model_fp.split('/')[-1].split('.')[0], 'modelout')\n",
    "    return out_file\n",
    "            \n",
    "                \n",
    "            \n",
    "# in worker, get smoldyn config from bucket\n",
    "# pass config through\n",
    "add_output_commands(model_fp, 10)\n",
    "        "
   ],
   "execution_count": 100,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T23:04:49.224332Z",
     "start_time": "2024-09-09T23:04:49.221326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open(model_fp, 'w') as file:\n",
    "    print(file.read())"
   ],
   "execution_count": 94,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T22:33:48.585104Z",
     "start_time": "2024-09-09T22:33:48.573829Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = list(range(20))\n",
    "\n",
    "x.insert(2, [1, 2, 3])"
   ],
   "execution_count": 56,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:26:55.595060Z",
     "start_time": "2024-09-09T21:26:55.565589Z"
    }
   },
   "cell_type": "code",
   "source": "comp = Composite(config={'state': doc}, core=CORE)",
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:27:53.766630Z",
     "start_time": "2024-09-09T21:27:06.577704Z"
    }
   },
   "cell_type": "code",
   "source": "comp.run(3)\n",
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-09T21:27:53.828012Z",
     "start_time": "2024-09-09T21:20:14.408302Z"
    }
   },
   "cell_type": "code",
   "source": "comp.gather_results()",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T17:29:26.986777Z",
     "start_time": "2024-09-18T17:29:25.659011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T17:29:39.340403Z",
     "start_time": "2024-09-18T17:29:36.860121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cobra\n",
    "from cobra.io import load_model\n",
    "model = load_model('textbook')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T17:33:47.271987Z",
     "start_time": "2024-09-18T17:33:47.266364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_dynamic_bounds(model, y):\n",
    "    \"\"\"Use external concentrations to bound the uptake flux of glucose.\"\"\"\n",
    "    biomass, glucose = y  # expand the boundary species\n",
    "    glucose_max_import = -10 * glucose / (5 + glucose)\n",
    "    model.reactions.EX_glc__D_e.lower_bound = glucose_max_import\n",
    "\n",
    "\n",
    "def dynamic_system(t, y):\n",
    "    \"\"\"Calculate the time derivative of external species.\"\"\"\n",
    "\n",
    "    biomass, glucose = y  # expand the boundary species\n",
    "\n",
    "    # Calculate the specific exchanges fluxes at the given external concentrations.\n",
    "    with model:\n",
    "        add_dynamic_bounds(model, y)\n",
    "\n",
    "        cobra.util.add_lp_feasibility(model)\n",
    "        feasibility = cobra.util.fix_objective_as_constraint(model)\n",
    "        lex_constraints = cobra.util.add_lexicographic_constraints(\n",
    "            model=model, \n",
    "            objectives=['Biomass_Ecoli_core', 'EX_glc__D_e'], \n",
    "            objective_direction=['max', 'max']\n",
    "        )\n",
    "\n",
    "    # Since the calculated fluxes are specific rates, we multiply them by the\n",
    "    # biomass concentration to get the bulk exchange rates.\n",
    "    fluxes = lex_constraints.values\n",
    "    fluxes *= biomass\n",
    "\n",
    "    # This implementation is **not** efficient, so I display the current\n",
    "    # simulation time using a progress bar.\n",
    "    if dynamic_system.pbar is not None:\n",
    "        dynamic_system.pbar.update(1)\n",
    "        dynamic_system.pbar.set_description('t = {:.3f}'.format(t))\n",
    "\n",
    "    return fluxes\n",
    "\n",
    "dynamic_system.pbar = None\n",
    "\n",
    "\n",
    "def infeasible_event(t, y):\n",
    "    \"\"\"\n",
    "    Determine solution feasibility.\n",
    "\n",
    "    Avoiding infeasible solutions is handled by solve_ivp's built-in event detection.\n",
    "    This function re-solves the LP to determine whether or not the solution is feasible\n",
    "    (and if not, how far it is from feasibility). When the sign of this function changes\n",
    "    from -epsilon to positive, we know the solution is no longer feasible.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    with model:\n",
    "\n",
    "        add_dynamic_bounds(model, y)\n",
    "\n",
    "        cobra.util.add_lp_feasibility(model)\n",
    "        feasibility = cobra.util.fix_objective_as_constraint(model)\n",
    "\n",
    "    return feasibility - infeasible_event.epsilon\n",
    "\n",
    "infeasible_event.epsilon = 1E-6\n",
    "infeasible_event.direction = 1\n",
    "infeasible_event.terminal = True"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T17:33:56.887142Z",
     "start_time": "2024-09-18T17:33:47.866866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ts = np.linspace(0, 15, 100)  # Desired integration resolution and interval\n",
    "y0 = [0.1, 10]\n",
    "\n",
    "with tqdm() as pbar:\n",
    "    dynamic_system.pbar = pbar\n",
    "\n",
    "    sol = solve_ivp(\n",
    "        fun=dynamic_system,\n",
    "        events=[infeasible_event],\n",
    "        t_span=(ts.min(), ts.max()),\n",
    "        y0=y0,\n",
    "        t_eval=ts,\n",
    "        rtol=1e-6,\n",
    "        atol=1e-8,\n",
    "        method='BDF'\n",
    "    )"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T17:33:56.894243Z",
     "start_time": "2024-09-18T17:33:56.891918Z"
    }
   },
   "cell_type": "code",
   "source": "sol",
   "execution_count": 10,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "execution_count": null,
   "source": "",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biosimulators-processes-JaN5cQMh-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
